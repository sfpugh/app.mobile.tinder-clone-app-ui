{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd030295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Profile Photo Verification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Use OpenPose FACE/COCO/MPI to find points on the body that specify the pose"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"face\": {\"proto\": 'pose/face/pose_deploy_linevec.prototxt', \"model\": 'pose/face/pose_iter_116000.caffemodel', \"points\": 18},\n",
    "            \"coco\": {\"proto\": 'pose/coco/pose_deploy_linevec.prototxt', \"model\": 'pose/coco/pose_iter_440000.caffemodel', \"points\": 18},\n",
    "            \"mpi\": {\"proto\": 'pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt', \"model\": 'pose/mpi/pose_iter_160000.caffemodel', \"points\": 15}}\n",
    "\n",
    "def detect_points(img, model, threshold=0):\n",
    "    (imgheight, imgwidth) = img.shape[:2]\n",
    "    inp = cv2.dnn.blobFromImage(img, 1.0 / 255, (imgheight, imgwidth), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # load OpenPose\n",
    "    net = cv2.dnn.readNetFromCaffe(params[model][\"proto\"], params[model][\"model\"])\n",
    "    net.setInput(inp)\n",
    "    out = net.forward()\n",
    "\n",
    "    H, W = out.shape[2:]\n",
    "\n",
    "    # Extract the pose data points, keep the ones where we are above threshold confidence that they are correct\n",
    "    points = []\n",
    "    points_kept = []\n",
    "    for i in range(params[model][\"points\"]):\n",
    "        probMap = out[0, i, :, :]\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        x = (imgwidth * point[0]) / W\n",
    "        y = (imgheight * point[1]) / H\n",
    "\n",
    "        if prob > threshold:\n",
    "            pt = (int(x), int(y))\n",
    "            points.append(pt)\n",
    "            points_kept.append(i)\n",
    "        else:\n",
    "            points.append(None)\n",
    "            \n",
    "    return points, points_kept"
   ]
  },
  {
   "source": [
    "## Check that the data points match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH = 1\n",
    "NO_MATCH = 0\n",
    "\n",
    "def check_for_match(img1_pts, img2_pts, max_deviation=1):\n",
    "    # Transform the data points such that the points from both images are centered horizontally and vertically\n",
    "    y_min1 = min([pt[1] for pt in img1_pts])\n",
    "    y_min2 = min([pt[1] for pt in img2_pts])\n",
    "    x_center1 = np.mean([pt[0] for pt in img1_pts])\n",
    "    x_center2 = np.mean([pt[0] for pt in img2_pts])\n",
    "    avg_center = np.mean([x_center1, x_center2])\n",
    "    trans_img1_data = [(avg_center + pt[0] - x_center1, pt[1] - y_min1) for pt in img1_pts]\n",
    "    trans_img2_data = [(avg_center + pt[0] - x_center2, pt[1] - y_min2) for pt in img2_pts]\n",
    "\n",
    "    # Plot the datapoints\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    ax.set_title(\"Data Points Superimposed\")\n",
    "    ax.scatter(*zip(*trans_img1_data), color='blue')\n",
    "    ax.scatter(*zip(*trans_img2_data), color='orange')\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    fig.show()\n",
    "\n",
    "    # Compute distances between each pair of data points\n",
    "    dist = lambda pt1, pt2 : ((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2)**(1/2)\n",
    "    pt_distances = list(map(dist, trans_img1_data, trans_img2_data))\n",
    "    #print(pt_distances)\n",
    "\n",
    "    # Determine if there are any outliers\n",
    "    mean = np.mean(pt_distances)\n",
    "    std = np.std(pt_distances)\n",
    "    #print(mean, std)\n",
    "\n",
    "    if any(pt_distances < mean - std * max_deviation) or any(pt_distances > mean + std * max_deviation):\n",
    "        return NO_MATCH\n",
    "\n",
    "    return MATCH"
   ]
  },
  {
   "source": [
    "# Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_img = cv2.imread('example/profile_photo.jpg')\n",
    "profile_img_gray = cv2.cvtColor(profile_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pose_img = cv2.imread('example/pose.jpg')\n",
    "pose_img_gray = cv2.cvtColor(pose_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "verification_img = cv2.imread('example/verification_photo.jpg')\n",
    "verification_img_gray = cv2.cvtColor(verification_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "bad_verification_img = cv2.imread('example/bad_verification_photo.jpg')\n",
    "bad_verification_img_gray = cv2.cvtColor(verification_img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "source": [
    "Try a pose that does match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data, img1_pts_kept = detect_points(pose_img, \"mpi\", threshold=0.5)\n",
    "img2_data, img2_pts_kept = detect_points(verification_img, \"mpi\", threshold=0.5)\n",
    "img3_data, img3_pts_kept = detect_points(profile_img, \"face\", threshold=0.5)\n",
    "img4_data, img4_pts_kept = detect_points(verification_img, \"face\", threshold=0.5)\n",
    "\n",
    "pts_to_keep = list(set.intersection(set(img1_pts_kept), set(img2_pts_kept)))\n",
    "img1_data = list(np.array(img1_data)[pts_to_keep])\n",
    "img2_data = list(np.array(img2_data)[pts_to_keep])\n",
    "print(len(pts_to_keep))     # TODO: should force min on this\n",
    "\n",
    "pts_to_keep = list(set.intersection(set(img3_pts_kept), set(img4_pts_kept)))\n",
    "img3_data = list(np.array(img3_data)[pts_to_keep])\n",
    "img4_data = list(np.array(img4_data)[pts_to_keep])\n",
    "print(len(pts_to_keep))     # TODO: should force min on this\n",
    "\n",
    "pose_match = check_for_match(img1_data, img2_data, max_deviation=3)\n",
    "face_match = check_for_match(img3_data, img4_data, max_deviation=2)\n",
    "\n",
    "if pose_match == MATCH and face_match == MATCH:\n",
    "    print(\"Verified\")\n",
    "else:\n",
    "    print(\"NOT Verified\")"
   ]
  },
  {
   "source": [
    "Try a pose that does not match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data, img1_pts_kept = detect_pose(pose_img, threshold=0.5)\n",
    "img2_data, img2_pts_kept = detect_pose(bad_verification_img, threshold=0.5)\n",
    "\n",
    "pts_to_keep = list(set.intersection(set(img1_pts_kept), set(img2_pts_kept)))\n",
    "img1_data = list(np.array(img1_data)[pts_to_keep])\n",
    "img2_data = list(np.array(img2_data)[pts_to_keep])\n",
    "print(len(pts_to_keep))\n",
    "\n",
    "pose_match = check_for_match(img1_data, img2_data, max_deviation=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}